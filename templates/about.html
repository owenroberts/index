{% extends "layout.html" %}
{% block index1 %}
{% endblock %}
{% block content %}

<strong>About</strong>
<div id="about">
<<<<<<< HEAD
	<p>1. Index I generates "new words" by affixing Greek & Latin prefixes to every noun in the English language. We have created an algorithm & a bot (called <a href="https://twitter.com/geneword" target="blank">Geneword</a>) that generates all possible combinations of prefixes and nouns, and can place the "new words" randomly in a range of texts of different genres and forms, using the Natural Language processing and the Markov chain algorithm. We are using two sets of nouns: the first is "all nouns," which consists of 55,191 words, and the second is a smaller set that we are calling "common nouns," which consists of 1525 words. By using 168 prefixes, the algorithm produces over 9 million "new words," not counting redundancies.</p>

	<p>The nouns and definitions are sourced from the <a href="https://wordnet.princeton.edu/" target="blank">WordNet database</a></p>
	<p>2. Text generator places the "new words" randomly in a range of texts of different genres and forms, using the NLTK to identify common nouns, and runs a Markov chain algorithm to generate new hybrid texts.</p>
	<p>3. Index I is designed to be a provocation, a starting point, for imagining what new set of expressive materials in the English language. With a simple gesture, the book aims to permanently expand the English language, and to find out what happens (expressively & poetically) when these new spaces are created. This feels important in a time when the language of power is being used to limit our vision on what we can do, rather than create new pathways of meaning-making / ways of being in the world.</p>
=======
	
	<p>About the project: [GENEWORD]</p>

	<p>Index I generates "new words" by affixing Greek & Latin prefixes to every noun in the English language. We have created an algorithm & a bot (called Geneword) that generates all possible combinations of prefixes and nouns, and can place the "new words" randomly in a range of texts of different genres and forms, using the Natural Language processing and the Markov chain algorithm. We are using two sets of nouns: the first is "all nouns," which consists of 55,191 words, and the second is a smaller set that we are calling "common nouns," which consists of 1525 words. By using 168 prefixes, the algorithm produces over 9 million "new words," not counting redundancies. </p>

	<p>This version:</p>

	<p>Due to the volume of words, Kaf has planned a series of curated expressions of the database (a sequence of sonnets with new words, a zine with multiple-prefix new words, and a dictionary). The next stage is the dictionary. This dictionary would have blank entries, and the it could either be printed as single huge edition (with all 9 million generated words), or as a short series with different prefixes (Teleword, Geneword, Mythoword, etc.), each using the 55,000 noun set. Again, the online component would ask to readers to participate in creating meaning from the words, as if it were poetry, thereby crowdsourcing future definitions.  </p>

	<p>Why this is meaningful now:</p>

	<p>The dictionary is designed to be a provocation, a starting point, for imagining what new set of expressive materials in the English language. With a simple gesture, the book aims to permanently expand the English language, and to find out what happens (expressively & poetically) when these new spaces are created. This feels important in a time when the language of power is being used to limit our vision on what we can do, rather than create new pathways of meaning-making / ways of being in the world.</p>

>>>>>>> 9ee6cfeb752df705f084ab94c47a52d067781595
	<strong>Bios</strong>
	<p>Tom Haviv is a writer, artist and educator based in New York City. His website is <a href="http://tomhaviv.com" target="blank">tomhaviv.com</a>.</p>
	<p>Owen Roberts is an artist and educator based in Brooklyn, New York and Shanghai, China. His work is available at <a href="http://owenroberts.github.io" target="blank">owenroberts.github.io</a>.</p>
	<p><a href="{{ url_for('static',filename='license.txt') }}"[>License</a></p>
	<p>Bird, Steven, Edward Loper and Ewan Klein (2009).<br>
	Natural Language Processing with Python.  O'Reilly Media Inc.</p>
</div>

{% endblock %}

{% block script %}
{% endblock %}